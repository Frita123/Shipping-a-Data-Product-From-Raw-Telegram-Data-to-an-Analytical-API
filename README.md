# Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API

ğŸ“¦ Shipping a Data Product: Telegram â†’ Analytical API
ğŸ“Œ Project Overview

This project builds an end-to-end data pipeline that:

Collects medical-related Telegram messages

Stores raw data in PostgreSQL

Transforms the data using dbt

Builds an analytical star schema warehouse

Prepares clean data for analytics and APIs

âœ… Task 1 â€” Data Ingestion & Raw Storage
ğŸ¯ Objective

Scrape Telegram messages

Clean and normalize the data

Store raw data in PostgreSQL

ğŸ›  What was done

Extracted Telegram messages using Python

Cleaned and structured the data

Created PostgreSQL tables

Loaded data into raw.telegram_messages

ğŸ“‚ Key Outputs

Raw messages stored in PostgreSQL

Reproducible ETL pipeline

Database ready for analytics transformation

âœ… Task 2 â€” Data Warehouse with dbt
ğŸ¯ Objective

Transform raw data into an analytical warehouse

Build a star schema using dbt

Add data quality tests and documentation

ğŸ›  What was done

Initialized dbt project (medical_warehouse)

Created models:

stg_telegram_messages (staging)

dim_channels

dim_dates

fct_messages

Implemented:

Not-null tests

Uniqueness tests

Relationship tests

Generated dbt documentation

ğŸ— Warehouse Schema

Fact Table: fct_messages

Dimensions: dim_channels, dim_dates